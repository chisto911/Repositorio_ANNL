{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller de Análisis Numérico Lineal: Integración Numérica\n",
    "**Fecha:** 9 de enero de 2026\n",
    "\n",
    "Este cuaderno contiene la solución rigurosa a los ejercicios planteados sobre métodos de integración numérica (Trapecio, Simpson, Romberg, Adaptativo) y análisis de errores para funciones suaves y singulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Configuración de gráficos\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Librerías cargadas correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Análisis Teórico de la Función $f(x)$\n",
    "\n",
    "Sea la función:\n",
    "$$ f(x) = e^{-x}\\cos(5x), \\quad x \\in [0, 2] $$\n",
    "\n",
    "### a) Justificación de suavidad ($C^{\\infty}$)\n",
    "La función $f(x)$ es el producto de dos funciones elementales:\n",
    "1. $h(x) = e^{-x}$ (Exponencial, $C^{\\infty}$ en $\\mathbb{R}$).\n",
    "2. $k(x) = \\cos(5x)$ (Trigonométrica, $C^{\\infty}$ en $\\mathbb{R}$).\n",
    "\n",
    "**Teorema:** El producto de funciones de clase $C^{\\infty}$ es de clase $C^{\\infty}$. Por tanto, $f(x)$ es infinitamente diferenciable en $[0, 2]$, sin singularidades ni discontinuidades.\n",
    "\n",
    "### b) Existencia y Unicidad de la Integral\n",
    "**Teorema:** Toda función continua en un intervalo cerrado y acotado $[a, b]$ es Riemann-integrable.\n",
    "Dado que $f \\in C^{\\infty}([0,2]) \\subset C^0([0,2])$, la integral $I_f = \\int_0^2 f(x)dx$ existe y es única."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función y parámetros\n",
    "def f(x):\n",
    "    return np.exp(-x) * np.cos(5*x)\n",
    "\n",
    "a, b = 0, 2\n",
    "\n",
    "# 2. Cálculo del valor de referencia (QUADPACK)\n",
    "I_ref, error_est = quad(f, a, b, epsabs=1e-12, epsrel=1e-12)\n",
    "\n",
    "print(f\"Valor de referencia (I_ref): {I_ref:.15f}\")\n",
    "print(f\"Error estimado por quad:     {error_est:.15e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Implementación de las Reglas de Integración Compuestas\n",
    "\n",
    "def composite_midpoint(func, a, b, n):\n",
    "    \"\"\"Regla del Punto Medio Compuesta\"\"\"\n",
    "    h = (b - a) / n\n",
    "    x_mid = np.linspace(a + h/2, b - h/2, n)\n",
    "    return h * np.sum(func(x_mid))\n",
    "\n",
    "def composite_trapezoidal(func, a, b, n):\n",
    "    \"\"\"Regla del Trapecio Compuesta\"\"\"\n",
    "    x = np.linspace(a, b, n + 1)\n",
    "    y = func(x)\n",
    "    h = (b - a) / n\n",
    "    return (h/2) * (y[0] + 2*np.sum(y[1:-1]) + y[-1])\n",
    "\n",
    "def composite_simpson(func, a, b, n):\n",
    "    \"\"\"Regla de Simpson 1/3 Compuesta (n debe ser par)\"\"\"\n",
    "    if n % 2 != 0:\n",
    "        raise ValueError(\"n debe ser par para Simpson\")\n",
    "    x = np.linspace(a, b, n + 1)\n",
    "    y = func(x)\n",
    "    h = (b - a) / n\n",
    "    return (h/3) * (y[0] + 4*np.sum(y[1:-1:2]) + 2*np.sum(y[2:-2:2]) + y[-1])\n",
    "\n",
    "# 4. y 5. Cálculos para n=4 y n=8\n",
    "results = []\n",
    "for n in [4, 8]:\n",
    "    im = composite_midpoint(f, a, b, n)\n",
    "    it = composite_trapezoidal(f, a, b, n)\n",
    "    is_ = composite_simpson(f, a, b, n)\n",
    "    \n",
    "    results.append({\n",
    "        \"n\": n,\n",
    "        \"Midpoint\": im,\n",
    "        \"Trapezoid\": it,\n",
    "        \"Simpson\": is_,\n",
    "        \"Err_Mid\": abs(I_ref - im),\n",
    "        \"Err_Trap\": abs(I_ref - it),\n",
    "        \"Err_Simp\": abs(I_ref - is_)\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis de Convergencia\n",
    "\n",
    "El orden empírico de convergencia $p$ se estima mediante:\n",
    "$$ p \\approx \\log_2\\left(\\frac{E(n_1)}{E(n_2)}\\right) $$\n",
    "\n",
    "* **Trapecio / Punto Medio:** Teóricamente $O(h^2) \\implies p \\approx 2$.\n",
    "* **Simpson:** Teóricamente $O(h^4) \\implies p \\approx 4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo del orden de convergencia empírico\n",
    "err_4 = df_results.iloc[0]\n",
    "err_8 = df_results.iloc[1]\n",
    "\n",
    "p_mid = np.log2(err_4[\"Err_Mid\"] / err_8[\"Err_Mid\"])\n",
    "p_trap = np.log2(err_4[\"Err_Trap\"] / err_8[\"Err_Trap\"])\n",
    "p_simp = np.log2(err_4[\"Err_Simp\"] / err_8[\"Err_Simp\"])\n",
    "\n",
    "print(f\"Orden de convergencia empírico (n=4 -> n=8):\")\n",
    "print(f\"Punto Medio: {p_mid:.2f} (Teórico: 2)\")\n",
    "print(f\"Trapecio:    {p_trap:.2f} (Teórico: 2)\")\n",
    "print(f\"Simpson:     {p_simp:.2f} (Teórico: 4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. y 7. Cálculos para n=16 y Análisis Oscilatorio\n",
    "\n",
    "n_16 = 16\n",
    "val_simp_16 = composite_simpson(f, a, b, n_16)\n",
    "val_trap_16 = composite_trapezoidal(f, a, b, n_16)\n",
    "\n",
    "print(f\"n=16 | Error Trapecio: {abs(I_ref - val_trap_16):.5e}\")\n",
    "print(f\"n=16 | Error Simpson:  {abs(I_ref - val_simp_16):.5e}\")\n",
    "\n",
    "# Visualización de la función\n",
    "x_plot = np.linspace(a, b, 200)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(x_plot, f(x_plot), label=r\"$f(x) = e^{-x}\\cos(5x)$\", color='blue')\n",
    "plt.title(\"Naturaleza oscilatoria de la función\")\n",
    "plt.axhline(0, color='black', lw=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del Efecto Oscilatorio\n",
    "La función tiene una frecuencia angular $\\omega = 5$. El error en Simpson depende de $f^{(4)}(x)$, que escala con $\\omega^4 = 625$. A pesar de esto, como $h$ disminuye, el factor $h^4$ domina y reduce el error rápidamente. Sin embargo, para $n$ muy pequeños (paso $h$ grande), la regla del trapecio puede \"cortar\" los ciclos de oscilación perdiendo información significativa, mientras que Simpson se adapta mejor a la curvatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Tabla de Romberg (Extrapolación de Richardson)\n",
    "\n",
    "# Matriz R para almacenar resultados\n",
    "R = np.zeros((3, 3))\n",
    "\n",
    "# Columna 0: Trapecio para n=1, 2, 4\n",
    "R[0, 0] = composite_trapezoidal(f, a, b, 1)\n",
    "R[1, 0] = composite_trapezoidal(f, a, b, 2)\n",
    "R[2, 0] = composite_trapezoidal(f, a, b, 4)\n",
    "\n",
    "# Columna 1: Extrapolación O(h^4) (Similar a Simpson)\n",
    "for i in range(1, 3):\n",
    "    R[i, 1] = (4**1 * R[i, 0] - R[i-1, 0]) / (4**1 - 1)\n",
    "\n",
    "# Columna 2: Extrapolación O(h^6) (Similar a Boole)\n",
    "for i in range(2, 3):\n",
    "    R[i, 2] = (4**2 * R[i, 1] - R[i-1, 1]) / (4**2 - 1)\n",
    "\n",
    "print(\"Tabla de Romberg:\")\n",
    "print(R)\n",
    "print(f\"\\nAproximación R_2,2: {R[2,2]:.15f}\")\n",
    "print(f\"Error R_2,2:        {abs(I_ref - R[2,2]):.5e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Análisis de Romberg\n",
    "**a) Hipótesis:** La extrapolación funciona porque $f \\in C^{\\infty}$, lo que permite expandir el error de la regla del trapecio en una serie de potencias pares de $h$ (Euler-Maclaurin).\n",
    "\n",
    "**b) Costo:** Romberg reutiliza evaluaciones anteriores. Para obtener $R_{2,2}$ solo se requirió calcular hasta $n=4$ trapecios, logrando una precisión superior a Simpson con el mismo número de evaluaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Integración Adaptativa (Simpson)\n",
    "\n",
    "x_nodes = [] # Para visualizar distribución de puntos\n",
    "\n",
    "def simpson_step(f, a, b):\n",
    "    c = (a + b) / 2\n",
    "    h = (b - a) / 2\n",
    "    return (h/3) * (f(a) + 4*f(c) + f(b))\n",
    "\n",
    "def adaptive_simpson_recursive(f, a, b, tol, whole_simpson):\n",
    "    c = (a + b) / 2\n",
    "    left_simpson = simpson_step(f, a, c)\n",
    "    right_simpson = simpson_step(f, c, b)\n",
    "    \n",
    "    # Estimación de error\n",
    "    error = (left_simpson + right_simpson - whole_simpson) / 15\n",
    "    \n",
    "    if abs(error) <= tol:\n",
    "        x_nodes.append(a); x_nodes.append(c); x_nodes.append(b)\n",
    "        return left_simpson + right_simpson + error\n",
    "    else:\n",
    "        return (adaptive_simpson_recursive(f, a, c, tol/2, left_simpson) + \n",
    "                adaptive_simpson_recursive(f, c, b, tol/2, right_simpson))\n",
    "\n",
    "def solve_adaptive(f, a, b, tol):\n",
    "    x_nodes.clear()\n",
    "    initial_simp = simpson_step(f, a, b)\n",
    "    return adaptive_simpson_recursive(f, a, b, tol, initial_simp)\n",
    "\n",
    "tol = 1e-6\n",
    "I_adapt = solve_adaptive(f, 0, 2, tol)\n",
    "unique_nodes = np.unique(x_nodes)\n",
    "\n",
    "print(f\"Resultado Adaptativo: {I_adapt:.15f}\")\n",
    "print(f\"Nodos únicos usados:  {len(unique_nodes)}\")\n",
    "print(f\"Error real:           {abs(I_ref - I_adapt):.5e}\")\n",
    "\n",
    "# Visualización del refinamiento\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.scatter(unique_nodes, np.zeros_like(unique_nodes), alpha=0.5, s=10, color='red')\n",
    "plt.title(\"Distribución de nodos (Refinamiento Adaptativo)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Análisis de función singular g(x)\n",
    "\n",
    "def g(x):\n",
    "    # Evitamos log(0) numérico, sabiendo que el límite es 0\n",
    "    val = np.sqrt(x) * np.log(x + 1)\n",
    "    return np.where(x==0, 0, val)\n",
    "\n",
    "# Referencia\n",
    "I_g_ref, _ = quad(g, 0, 1)\n",
    "\n",
    "# Comparación\n",
    "n_g = 32\n",
    "trap_g = composite_trapezoidal(g, 0, 1, n_g)\n",
    "simp_g = composite_simpson(g, 0, 1, n_g)\n",
    "adapt_g = solve_adaptive(g, 0, 1, 1e-6)\n",
    "\n",
    "print(f\"Referencia g(x): {I_g_ref:.10f}\")\n",
    "print(f\"Trapecio (n={n_g}): {trap_g:.10f} | Error: {abs(I_g_ref - trap_g):.5e}\")\n",
    "print(f\"Simpson (n={n_g}):  {simp_g:.10f} | Error: {abs(I_g_ref - simp_g):.5e}\")\n",
    "print(f\"Adaptativo:      {adapt_g:.10f} | Error: {abs(I_g_ref - adapt_g):.5e}\")\n",
    "\n",
    "# Gráfica de g(x)\n",
    "plt.figure(figsize=(10,4))\n",
    "x_vals = np.linspace(0, 1, 500)\n",
    "plt.plot(x_vals, g(x_vals))\n",
    "plt.title(r\"$g(x) = \\sqrt{x}\\ln(x+1)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la Singularidad de $g(x)$\n",
    "**a) No pertenencia a $C^2$:**\n",
    "Cerca de 0, $g(x) \\approx x^{3/2}$. Su segunda derivada es $g''(x) \\approx \\frac{3}{4}x^{-1/2}$.\n",
    "Cuando $x \\to 0$, $g''(x) \\to \\infty$. La función no tiene segunda derivada acotada en $[0,1]$, lo que viola las hipótesis de error para Trapecio y Simpson.\n",
    "\n",
    "**b) Consecuencia:**\n",
    "Simpson pierde su orden de convergencia $O(h^4)$ y se vuelve ineficiente. El método adaptativo, sin embargo, detecta el error masivo cerca de 0 y refina agresivamente en esa zona, manteniendo la precisión global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Conclusiones Finales\n",
    "\n",
    "1. **Selección de Método:**\n",
    "    * *Suaves:* Romberg o Gauss (Alta eficiencia).\n",
    "    * *Oscilatorias:* Adaptativos de alto orden o Filon.\n",
    "    * *Singulares:* Adaptativos o cambio de variable.\n",
    "\n",
    "2. **Universalidad:**\n",
    "    No existe un método universal. La eficiencia depende estrictamente de la regularidad (suavidad) de la función. Los métodos robustos (adaptativos) son más seguros pero computacionalmente más costosos si no son necesarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
